{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the Execution of the statistical models used in the thesis (pipeline function). The model functions are defined. The datasets for the analysis are created given data has been preprocessed (downsampled, filtered). The data is originally structured in tseries each containing a set of trials that belong together. The tseries are combined to leverage all data of the desired type (complex_sub, pure). Arrays that store the CV-metrics are created and saved depending on the CV method. For each setting (delay, duration of spectrogram (T), number of components (R)) the models are fitted and CV-scores are computed insample and out-of-sample.\n",
    "The data is stored at FIAS. These files should be executed once the auditorycoding directory folder (as on the fias server) is placed in the same directory as these files. A \"temp\" folder should be created to store temporary CV-folds is mode=drive is used. Also a \"Linear Mappings\" directory should be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.cross_decomposition import CCA as CCAsklearn\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pls_regression import PLSRegression as PLSRegressionEdited\n",
    "from pls_regression import CCA as CCAEdited\n",
    "from pls_regression import PLSCanonical as PLSCanonicalEdited\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import os\n",
    "\n",
    "from preprocessing_final import preprocessing, reverse_preprocessing_img, generate_masks, cv_split_LOO, select_stimulus_subset, preprocessing_pure, cv_split_trial, cv_split_newstim, preprocessing_mps\n",
    "from audio_processing_final import create_spectrograms, plot_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    X_c = (X - np.mean(X, axis=0) )/ np.std(X, axis=0)\n",
    "    return X_c\n",
    "\n",
    "class CCA():\n",
    "    \"\"\"Implementation of Canonical correlation analysis following the Paper:\n",
    "    https://dl.acm.org/doi/10.1145/3136624, https://doi.org/10.1145/3136624\n",
    "    n_components sets the number of components in the model, mode the solution to the CCA problem\n",
    "    eig should be used, ridge sets the value deducted from the diagonal of correlation matrices.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_components=2, mode=\"eig\", ridge=False):\n",
    "        self.mode = mode\n",
    "        self.n_components = n_components\n",
    "        self.ridge = ridge\n",
    "        \n",
    "    def standardize(self, X):\n",
    "        X_c = (X - np.mean(X, axis=0) )/ np.std(X, axis=0)\n",
    "        return X_c\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        N = X.shape[0]\n",
    "        Cxx = (1 / N) * X.T @ X\n",
    "        Cyy = (1 / N) * Y.T @ Y\n",
    "        Cxy = (1 / N) * X.T @ Y\n",
    "        Cyx = (1 / N) * Y.T @ X\n",
    "        \n",
    "        if self.mode == \"eig\":\n",
    "            if self.ridge == False:\n",
    "                R = np.linalg.inv(Cyy) @ Cyx @ np.linalg.inv(Cxx) @ Cxy\n",
    "                eigvals, eigvecs = np.linalg.eig(R)\n",
    "                self.correlations = np.sqrt(eigvals)\n",
    "                self.wy = eigvecs[:,:self.n_components]\n",
    "                self.wx = (np.linalg.inv(Cxx) @ Cxy @ self.wy) / self.correlations[:self.n_components]\n",
    "\n",
    "            if self.ridge != False:\n",
    "                print(\"ridge\")\n",
    "                R = np.linalg.inv(Cyy - self.ridge * np.identity(Cyy.shape[0])) @ Cyx @ np.linalg.inv(Cxx - self.ridge * np.identity(Cxx.shape[0])) @ Cxy\n",
    "                eigvals, eigvecs = np.linalg.eig(R)\n",
    "                eigvals, eigvecs = np.real(eigvals), np.real(eigvecs)\n",
    "                self.correlations = np.sqrt(eigvals)\n",
    "                self.wy = eigvecs[:,:self.n_components]\n",
    "                self.wx = (np.linalg.inv(Cxx- self.ridge * np.identity(Cxx.shape[0])) @ Cxy @ self.wy) / self.correlations[:self.n_components]\n",
    "            \n",
    "            return self.wx, self.wy, self.correlations\n",
    "            \n",
    "        elif self.mode == \"gen_eig\":\n",
    "            print(\"not implemented\")\n",
    "            pass\n",
    "            \n",
    "        elif self.mode == \"svd\":\n",
    "            CCxx = np.linalg.cholesky(Cxx)\n",
    "            CCyy = np.linalg.cholesky(Cyy)\n",
    "\n",
    "            U, s, V = np.linalg.svd(np.linalg.inv(CCxx) @ Cxy @ np.linalg.inv(CCyy), full_matrices=False)\n",
    "            \"\"\"S = np.zeros((4,3))\n",
    "            for i in range(len(s)):\n",
    "                S[i,i] = s[i]\"\"\"\n",
    "            self.wx = np.linalg.inv(CCxx) @ U[:,:self.n_components]\n",
    "            self.wy = np.linalg.inv(CCyy) @ V[:,:self.n_components].T\n",
    "            self.correclations = s\n",
    "            \n",
    "            return self.wx, self.wy, self.correclations\n",
    "        \n",
    "    def predict(self, X):\n",
    "        Y_hat = X @ self.wx @ self.wy.T\n",
    "        return Y_hat\n",
    "        \n",
    "class RRR():\n",
    "    \"\"\"Reduced rank regression model adapted from https://github.com/berenslab/patch-seq-rrr\n",
    "    ridge sets regularization parameter (alpha).\n",
    "    \"\"\"\n",
    "    def __init__(self, ridge=False):\n",
    "        self.ridge = ridge\n",
    "\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        U,s,V = np.linalg.svd(X, full_matrices=False)\n",
    "        if self.ridge != False:\n",
    "            self.B = V.T @ np.linalg.inv(np.diag(s**2) + self.ridge * np.identity(s.shape[0])) @ np.diag(s) @ U.T @ Y\n",
    "\n",
    "        elif self.ridge == False:\n",
    "            self.B = V.T @ np.diag(s/(s**2)) @ U.T @ Y\n",
    "\n",
    "        self.U,self.s,self.V = np.linalg.svd(X@self.B, full_matrices=False)\n",
    "\n",
    "\n",
    "    def predict(self, X, rank):\n",
    "        w = self.B @ self.V.T[:,:rank]\n",
    "        v = self.V.T[:,:rank]\n",
    "\n",
    "        pos = np.argmax(np.abs(v), axis=0)\n",
    "        flips = np.sign(v[pos, range(v.shape[1])])\n",
    "        v = v * flips\n",
    "        w = w * flips\n",
    "        return X @ w @ v.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(method, dataset, subset=None, subset_predict=None,\n",
    "             relevance_cutoff=0.25,\n",
    "             ds=4, \n",
    "             input_durations=[1.5], \n",
    "             delays=[0], \n",
    "             components=range(1,51,2), \n",
    "             cv_mode=\"trial\", \n",
    "             cv_splits=5,\n",
    "             save=True,\n",
    "             reverse_direction=False,\n",
    "             single_input=False,\n",
    "             ridge=False,\n",
    "             datamode=\"filtered\",\n",
    "             mps=False):\n",
    "    \"\"\"This function contains the main computations for the regression models.\n",
    "    method = [PCR, LR, RRR, CCA, PLS]\n",
    "    dataset = [pure, complex_sub]\n",
    "    subset and subset_predict should remain as None\n",
    "    relevance_cutoff = see create_masks in preprocessing\n",
    "    ds = downsampling factor\n",
    "    input_durations = list of duration of spectrograms to be tested (sec)\n",
    "    delays = list of delays b/w stimulus and reaction\n",
    "    components = list of number of components (R) to keep in model\n",
    "    cv_mode = [default (random CV), trial (trial CV), newstim (stimulus CV)]\n",
    "    cv_splits = 5 but has no effect on CV methods\n",
    "    save has no effect\n",
    "    reverse_direction yields backwards predictions if True\n",
    "    single input represents pure tones as single feature instead of spectrogram\n",
    "    ridge = alpha hyperparameter for LR (MLR) and RRR (RRRR)\n",
    "    datamode should be set to filtered but deconv works\n",
    "    mps changes spectrograms to modulation power spectrograms\n",
    "    \n",
    "    \"\"\"\n",
    "    # Select tseries that are part of dataset\n",
    "    spectrograms = create_spectrograms(FFT_overlap=0, plot=False, scaling=\"decibels\")\n",
    "    tseries = []\n",
    "    stimuli = []\n",
    "    numTrials = 0\n",
    "    if \"pure\" in dataset:\n",
    "        tseries.extend([f\"tseries_{i}\" for i in [28, 33, 34, 39]])\n",
    "        stimulus = np.load(\"auditorycoding/F189/tseries_28/stimulus.npy\")\n",
    "        stim_set = set([s[0] + 203 for s in stimulus])\n",
    "        if single_input == False:\n",
    "            stim_set.difference_update({213, 214, 215})\n",
    "        stimuli.extend(stim_set)\n",
    "        numTrials += 32\n",
    "    if \"complex_full\" in dataset:\n",
    "        tseries.extend([f\"tseries_{i}\" for i in [21, 24, 27, 31, 36, 38]])\n",
    "        stimulus = np.load(\"auditorycoding/F189/tseries_21/stimulus.npy\")\n",
    "        stimuli.extend(set([s[0] for s in stimulus]))\n",
    "    if  \"complex_sub\" in dataset:\n",
    "        tseries.extend([f\"tseries_{i}\" for i in [23, 26, 29, 32, 37]])\n",
    "        stimulus = np.load(\"auditorycoding/F189/tseries_23/stimulus.npy\")\n",
    "        stimuli.extend(set([s[0] for s in stimulus]))\n",
    "        numTrials += (15 - 7)\n",
    "    if \"mov\" in dataset:\n",
    "        tseries.extend([f\"tseries_{i}\" for i in [25, 30]])\n",
    "        # ???? TBD\n",
    "        stimulus = np.load(\"auditorycoding/F189/tseries_28/stimulus.npy\")\n",
    "        stimuli.extend([s[0] + 203 for s in stimulus])\n",
    "\n",
    "\n",
    "    if subset_predict != None:\n",
    "        stimuli = subset_predict\n",
    "    \n",
    "    # Create the matrices to store evaluation metrics, the size of shich depends on direction,\n",
    "    # dataset, datamode, input representation and CV method\n",
    "    # Metrics available are explained variance (evs), mean absolute percentage error (mape)\n",
    "    #, and mean squared error (mse)\n",
    "    if reverse_direction == False:\n",
    "        if datamode == \"deconv\":\n",
    "            output_size = {0.25: 3053} #Size of Y-imageds depending on mask\n",
    "        elif datamode != \"deconv\":\n",
    "            output_size = {0: 3347, 0.25: 3072, 0.5:2648, 0.75: 2240}\n",
    "\n",
    "    elif reverse_direction == True:\n",
    "        if single_input == True:\n",
    "            output_size = {relevance_cutoff: 1}\n",
    "\n",
    "        elif single_input == False:\n",
    "            if mps == False:\n",
    "                output_size = {relevance_cutoff: int(15 * max(input_durations)) * len(spectrograms[0][1])}\n",
    "            elif mps == True:\n",
    "                output_size = {relevance_cutoff: int(77*101)}\n",
    "    \n",
    "    if method not in [\"CCA\", \"PLS\", \"RRR\", \"PCR\", \"EN\", \"PLSCAN\"]:\n",
    "        components = [0] # Linear regression has no components\n",
    "\n",
    "    if cv_mode == \"default\":\n",
    "        evs_scores = np.zeros((len(delays), len(input_durations), len(components), cv_splits, output_size[relevance_cutoff]))\n",
    "        mape_scores = np.zeros((len(delays), len(input_durations), len(components), cv_splits, output_size[relevance_cutoff]))\n",
    "        mse_scores = np.zeros((len(delays), len(input_durations), len(components), cv_splits, output_size[relevance_cutoff]))\n",
    "\n",
    "        evs_scores_insample = np.zeros((len(delays), len(input_durations), len(components), cv_splits, output_size[relevance_cutoff]))\n",
    "        mape_scores_insample = np.zeros((len(delays), len(input_durations), len(components), cv_splits, output_size[relevance_cutoff]))\n",
    "        mse_scores_insample = np.zeros((len(delays), len(input_durations), len(components), cv_splits, output_size[relevance_cutoff]))\n",
    "\n",
    "    elif cv_mode == \"loo\":\n",
    "        evs_scores = np.zeros((len(delays), len(input_durations), len(components), len(stimuli), output_size[relevance_cutoff]))\n",
    "        mape_scores = np.zeros((len(delays), len(input_durations), len(components), len(stimuli), output_size[relevance_cutoff]))   \n",
    "        mse_scores = np.zeros((len(delays), len(input_durations), len(components), len(stimuli), output_size[relevance_cutoff]))\n",
    "\n",
    "        evs_scores_insample = np.zeros((len(delays), len(input_durations), len(components), len(stimuli), output_size[relevance_cutoff]))\n",
    "        mape_scores_insample = np.zeros((len(delays), len(input_durations), len(components), len(stimuli), output_size[relevance_cutoff]))   \n",
    "        mse_scores_insample = np.zeros((len(delays), len(input_durations), len(components), len(stimuli), output_size[relevance_cutoff]))    \n",
    "\n",
    "    elif cv_mode == \"trial\":\n",
    "        evs_scores = np.zeros((len(delays), len(input_durations), len(components), numTrials, output_size[relevance_cutoff]))\n",
    "        mape_scores = np.zeros((len(delays), len(input_durations), len(components), numTrials, output_size[relevance_cutoff]))\n",
    "        mse_scores = np.zeros((len(delays), len(input_durations), len(components), numTrials, output_size[relevance_cutoff]))\n",
    "\n",
    "        evs_scores_insample = np.zeros((len(delays), len(input_durations), len(components), numTrials, output_size[relevance_cutoff]))\n",
    "        mape_scores_insample = np.zeros((len(delays), len(input_durations), len(components), numTrials, output_size[relevance_cutoff]))\n",
    "        mse_scores_insample = np.zeros((len(delays), len(input_durations), len(components), numTrials, output_size[relevance_cutoff]))\n",
    "\n",
    "    elif cv_mode == \"newstim\":\n",
    "        evs_scores = np.zeros((len(delays), len(input_durations), len(components), 11, output_size[relevance_cutoff]))\n",
    "        mape_scores = np.zeros((len(delays), len(input_durations), len(components), 11, output_size[relevance_cutoff]))   \n",
    "        mse_scores = np.zeros((len(delays), len(input_durations), len(components), 11, output_size[relevance_cutoff]))\n",
    "\n",
    "        evs_scores_insample = np.zeros((len(delays), len(input_durations), len(components), 11, output_size[relevance_cutoff]))\n",
    "        mape_scores_insample = np.zeros((len(delays), len(input_durations), len(components), 11, output_size[relevance_cutoff]))   \n",
    "        mse_scores_insample = np.zeros((len(delays), len(input_durations), len(components), 11, output_size[relevance_cutoff]))       \n",
    "\n",
    "    # for each setting we create datamatrices by stacking the input and output matrices from each tseries ontop of each other    \n",
    "    max_components = max(components)\n",
    "    for i, d in tqdm(enumerate(delays)):\n",
    "        for j, duration in tqdm(enumerate(input_durations)):\n",
    "            input_seconds = duration\n",
    "            delay = d\n",
    "            if single_input == True:\n",
    "                X_cut, Y_cut, ft_cut, frame_idx_cut, frame_trial_idx_cut = preprocessing_pure(tseries[0],\n",
    "                relevance_cutoff=relevance_cutoff, ds=ds, delay=delay, mode=datamode)[2:]\n",
    "                \n",
    "                for series in tseries[1:]:\n",
    "                    Xi_cut, Yi_cut, fti_cut, framei_idx_cut, framei_trial_idx_cut = preprocessing_pure(series,\n",
    "                    relevance_cutoff=relevance_cutoff, ds=ds, delay=delay, mode=datamode)[2:]\n",
    "                    X_cut = np.vstack((X_cut, Xi_cut))\n",
    "                    Y_cut = np.vstack((Y_cut, Yi_cut))\n",
    "                    frame_idx_cut = np.append(frame_idx_cut, framei_idx_cut)\n",
    "                    frame_trial_idx_cut = np.append(frame_trial_idx_cut, framei_trial_idx_cut + frame_trial_idx_cut.max())\n",
    "\n",
    "            elif single_input == False:\n",
    "                if mps == False:\n",
    "                    X_cut, Y_cut, ft_cut, frame_idx_cut, frame_trial_idx_cut = preprocessing(tseries[0], spectrograms=spectrograms,\n",
    "                    relevance_cutoff=relevance_cutoff, input_seconds=input_seconds, ds=ds, delay=delay, mode=datamode)[2:]\n",
    "\n",
    "                    for series in tseries[1:]:\n",
    "                        Xi_cut, Yi_cut, fti_cut, framei_idx_cut, framei_trial_idx_cut = preprocessing(series, spectrograms=spectrograms,\n",
    "                        relevance_cutoff=relevance_cutoff, input_seconds=input_seconds, ds=ds, delay=delay, mode=datamode)[2:]\n",
    "                        X_cut = np.vstack((X_cut, Xi_cut))\n",
    "                        Y_cut = np.vstack((Y_cut, Yi_cut))\n",
    "                        frame_idx_cut = np.append(frame_idx_cut, framei_idx_cut)\n",
    "                        frame_trial_idx_cut = np.append(frame_trial_idx_cut, framei_trial_idx_cut + frame_trial_idx_cut.max())\n",
    "                elif mps == True:\n",
    "                    X_cut, Y_cut, ft_cut, frame_idx_cut, frame_trial_idx_cut = preprocessing_mps(tseries[0],\n",
    "                    relevance_cutoff=relevance_cutoff, ds=ds, delay=delay, mode=datamode)[2:]\n",
    "\n",
    "                    for series in tseries[1:]:\n",
    "                        Xi_cut, Yi_cut, fti_cut, framei_idx_cut, framei_trial_idx_cut = preprocessing_mps(series,\n",
    "                        relevance_cutoff=relevance_cutoff, ds=ds, delay=delay, mode=datamode)[2:]\n",
    "                        X_cut = np.vstack((X_cut, Xi_cut))\n",
    "                        Y_cut = np.vstack((Y_cut, Yi_cut))\n",
    "                        frame_idx_cut = np.append(frame_idx_cut, framei_idx_cut)\n",
    "                        frame_trial_idx_cut = np.append(frame_trial_idx_cut, framei_trial_idx_cut + frame_trial_idx_cut.max())\n",
    "                \n",
    "                #print(X_cut.shape, Y_cut.shape)\n",
    "            if subset:\n",
    "                X_cut, Y_cut, frame_idx_cut, frame_trial_idx_cut = select_stimulus_subset(X_cut, \n",
    "                                                                                          Y_cut, \n",
    "                                                                                          frame_idx_cut, \n",
    "                                                                                          frame_trial_idx_cut, \n",
    "                                                                                          subset)\n",
    "            \n",
    "            # Remove faulty trials\n",
    "\n",
    "            if \"complex_sub\" in dataset:\n",
    "                invalid_trials = [1,2,7,9,11,13,15]\n",
    "                valid_trials = set(frame_trial_idx_cut).difference(invalid_trials)\n",
    "                valid_idx = [a for a in range(len(frame_trial_idx_cut))\n",
    "                             if any(frame_trial_idx_cut[a] == b for b in valid_trials)]\n",
    "                X_cut = X_cut[valid_idx,:]\n",
    "                Y_cut = Y_cut[valid_idx,:]\n",
    "                frame_idx_cut = frame_idx_cut[valid_idx]\n",
    "                frame_trial_idx_cut = frame_trial_idx_cut[valid_idx]\n",
    "                \n",
    "            \n",
    "            if reverse_direction == True:\n",
    "                X_cut, Y_cut = Y_cut, X_cut\n",
    "            \n",
    "            # Select CV method and fit model for each split\n",
    "            if cv_mode == \"default\":\n",
    "                splits_X, splits_Y = cv_split(X_cut, Y_cut)\n",
    "\n",
    "            elif cv_mode == \"loo\":\n",
    "                splits_X, splits_Y = cv_split_LOO(X_cut, Y_cut, frame_idx_cut, index_set=subset_predict, mode=\"drive\")\n",
    "\n",
    "            elif cv_mode == \"trial\":\n",
    "                splits_X, splits_Y = cv_split_trial(X_cut, Y_cut, frame_trial_idx_cut, index_set=subset_predict, mode=\"drive\")\n",
    "                #splits_X, splits_Y = splits_X, splits_Y\n",
    "\n",
    "            elif cv_mode == \"newstim\":\n",
    "                splits_X, splits_Y = cv_split_newstim(X_cut, Y_cut, frame_idx_cut, frame_trial_idx_cut, index_set=subset_predict, mode=\"drive\", reverse_direction=reverse_direction)\n",
    "                \n",
    "            \n",
    "            for split in tqdm(range(len(splits_X))):\n",
    "                if cv_mode == \"default\":\n",
    "                    X_train, X_test = splits_X[split]\n",
    "                    Y_train, Y_test = splits_Y[split]\n",
    "\n",
    "                if cv_mode in [\"loo\", \"trial\", \"newstim\"]:\n",
    "                    X_train = np.load(splits_X[split][0])\n",
    "                    X_test = np.load(splits_X[split][1])\n",
    "\n",
    "                    Y_train = np.load(splits_Y[split][0])\n",
    "                    Y_test = np.load(splits_Y[split][1])\n",
    "\n",
    "\n",
    "                # Z-Score Data\n",
    "                X_scaler = StandardScaler().fit(X_train)\n",
    "                Y_scaler = StandardScaler().fit(Y_train)\n",
    "\n",
    "                \n",
    "                \n",
    "                # Potential tests for multicollinearity\n",
    "                #eigvals = np.linalg.eigvals(X_scaler.transform(X_train).T @ X_scaler.transform(X_train))\n",
    "                #print(\"Eigvals close to Zero: \", len(np.where(np.isclose(eigvals, 0))[0]))\n",
    "                #sorted_eigvals =  np.sort(eigvals)\n",
    "                #print(\"Sorted Eigvals: \",sorted_eigvals)\n",
    "\n",
    "                # Train models\n",
    "                if method == \"PLS\":\n",
    "                    model = PLSRegressionEdited(n_components=min(max_components, X_train.shape[1]),scale=False)\n",
    "                    model.fit(X_scaler.transform(X_train), Y_scaler.transform(Y_train))\n",
    "                if method == \"PLSCAN\":\n",
    "                    model = PLSCanonicalEdited(n_components=min(max_components, X_train.shape[1]),scale=False)\n",
    "                    model.fit(X_scaler.transform(X_train), Y_scaler.transform(Y_train))\n",
    "                if method == \"RRR\":\n",
    "                    model = RRR(ridge=ridge)\n",
    "                    model.fit(X_scaler.transform(X_train), Y_scaler.transform(Y_train))\n",
    "\n",
    "                \n",
    "                \n",
    "                for l, c in enumerate(components):\n",
    "                    # Predict test data for each number of components\n",
    "                    # Out of sample metrics\n",
    "                    \n",
    "                    if method == \"CCA\":\n",
    "                        model = CCA(n_components=c, mode=\"eig\", ridge=ridge)\n",
    "                        model.fit(X_scaler.transform(X_train), Y_scaler.transform(Y_train))\n",
    "                        Y_pred = Y_scaler.transform(Y_test)\n",
    "                    if method == \"PCR\":\n",
    "                        model = model = make_pipeline(PCA(n_components=c), LinearRegression())\n",
    "                        model.fit(X_scaler.transform(X_train), Y_scaler.transform(Y_train))\n",
    "                        Y_pred = model.predict(X_scaler.transform(X_test))\n",
    "                    elif method == \"LR\":\n",
    "                        model = Ridge(alpha=ridge)\n",
    "                        model.fit(X_scaler.transform(X_train), Y_scaler.transform(Y_train))\n",
    "                        Y_pred = model.predict(X_scaler.transform(X_test))\n",
    "                    elif method == \"EN\":\n",
    "                        model = ElasticNet(alpha=c[0], l1_ratio=c[1], fit_intercept=False,selection=\"random\")\n",
    "                        model.fit(X_scaler.transform(X_train), Y_scaler.transform(Y_train))  \n",
    "                        Y_pred = model.predict(X_scaler.transform(X_test))  \n",
    "                    elif method in [\"PLS\", \"RRR\", \"PLSCAN\"]:    \n",
    "                        Y_pred = model.predict(X_scaler.transform(X_test), rank=c)\n",
    "\n",
    "                    evs = explained_variance_score(Y_test, Y_scaler.inverse_transform(Y_pred), multioutput=\"raw_values\")\n",
    "                    mape = mean_absolute_percentage_error(Y_test, Y_scaler.inverse_transform(Y_pred), multioutput=\"raw_values\")\n",
    "                    mse = mean_squared_error(Y_test, Y_scaler.inverse_transform(Y_pred), multioutput=\"raw_values\")\n",
    "                    \n",
    "                    evs_scores[i,j,l,split,:] = evs\n",
    "                    mape_scores[i,j,l,split,:] = mape\n",
    "                    mse_scores[i,j,l,split,:] = mse\n",
    "                    \n",
    "                    if cv_mode == \"loo\":\n",
    "                        # not used\n",
    "                        np.save(f\"LOO_Partitions/{method}_{'_'.join(dataset)}_subeset_{subset}_{delay}_{input_seconds}_{split}_{c}_{reverse_direction}_single{single_input}_true.npy\", Y_test)\n",
    "                        np.save(f\"LOO_Partitions/{method}_{'_'.join(dataset)}_subeset_{subset}_{delay}_{input_seconds}_{split}_{c}_{reverse_direction}_single{single_input}_pred.npy\", Y_scaler.inverse_transform(Y_pred))\n",
    "                    \n",
    "                    # In-sample metrics\n",
    "                    if method == \"PCR\":\n",
    "                        Y_pred = model.predict(X_scaler.transform(X_train))\n",
    "                    if method == \"CCA\":\n",
    "                        Y_pred = Y_scaler.transform(Y_train)\n",
    "                    elif method == \"LR\":\n",
    "                        Y_pred = model.predict(X_scaler.transform(X_train))\n",
    "                    elif method == \"EN\":\n",
    "                        Y_pred = model.predict(X_scaler.transform(X_train))\n",
    "                        print(X_train.shape, Y_pred.shape, Y_train.shape) \n",
    "                    elif method in [\"PLS\", \"RRR\", \"PLSCAN\"]:    \n",
    "                        Y_pred = model.predict(X_scaler.transform(X_train), rank=c)\n",
    "\n",
    "                    evs = explained_variance_score(Y_train, Y_scaler.inverse_transform(Y_pred), multioutput=\"raw_values\")\n",
    "                    mape = mean_absolute_percentage_error(Y_train, Y_scaler.inverse_transform(Y_pred), multioutput=\"raw_values\")\n",
    "                    mse = mean_squared_error(Y_train, Y_scaler.inverse_transform(Y_pred), multioutput=\"raw_values\")\n",
    "                    \n",
    "                    evs_scores_insample[i,j,l,split,:] = evs\n",
    "                    mape_scores_insample[i,j,l,split,:] = mape\n",
    "                    mse_scores_insample[i,j,l,split,:] = mse\n",
    "\n",
    "            # Save scores of the model for each setting and split\n",
    "\n",
    "            if reverse_direction == False:\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_evs_ridge{ridge}.npy\", evs_scores)\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_mape_ridge{ridge}.npy\", mape_scores)\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_mse_ridge{ridge}.npy\", mse_scores)\n",
    "\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_evs_insample_ridge{ridge}.npy\", evs_scores_insample)\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_mape_insample_ridge{ridge}.npy\", mape_scores_insample)\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_mse_insample_ridge{ridge}.npy\", mse_scores_insample)\n",
    "\n",
    "            elif reverse_direction == True:\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_duration{input_durations}_evs_ridge{ridge}.npy\", evs_scores)\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_duration{input_durations}_mape_ridge{ridge}.npy\", mape_scores)\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_duration{input_durations}_mse_ridge{ridge}.npy\", mse_scores)\n",
    "\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_duration{input_durations}_evs_insample_ridge{ridge}.npy\", evs_scores_insample)\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_duration{input_durations}_mape_insample_ridge{ridge}.npy\", mape_scores_insample)\n",
    "                np.save(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_{reverse_direction}_single{single_input}_duration{input_durations}_mse_insample_ridge{ridge}.npy\", mse_scores_insample)                \n",
    "\n",
    "            pickle.dump(model, open(f\"Linear Mapping/{method}_{'_'.join(dataset)}_subeset_{subset}_{cv_mode}_delay{d}_duration{duration}_{reverse_direction}_single{single_input}_ridge{ridge}.p\", \"wb\"))\n",
    "            temp = os.listdir(\"temp/\")\n",
    "            for file_ in temp:\n",
    "                os.remove(f\"temp/{file_}\")\n",
    "                \n",
    "    return evs_scores, mape_scores, mse_scores\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f292722d6d50c2426abae6fd15a85386b49c5393ec98f1c35f79e4e4dd7448b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
